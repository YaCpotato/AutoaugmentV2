[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 15593128354797064850
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 13019479261499733125
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 12433943049761676835
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 10328878095490214143
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 116327722149926766
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 1228080377381425916
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 7181379053548889026
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 9547431185078028411
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 2383882072387548858
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 15520686904380423677
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 128)  18560       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 128)  0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 128)  147584      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 128)  2176        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 128)  147584      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 128)  147584      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 128)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 128)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 128)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 128)  147584      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 128)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 256)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 256)  33024       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 256)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 256)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 256)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 256)  590080      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 256)  0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 256)  590080      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 256)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 256)  590080      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 256)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 256)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 256)  590080      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 256)  1024        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 256)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 256)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 512)    2048        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 512)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 512)    0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 512)    131584      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 512)    2359808     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 512)    2048        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 512)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 512)    0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 512)    2048        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 512)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 512)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 512)    2359808     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 512)    0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 512)    2048        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 512)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 512)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 512)    2359808     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 512)    2048        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 512)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 8, 8, 512)    0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 512)    2048        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 512)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 512)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           5130        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 23,377,290
Trainable params: 23,362,922
Non-trainable params: 14,368
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/30
 - 57s - loss: 3.1108 - acc: 0.3131 - val_loss: 1.9176 - val_acc: 0.3180
Epoch 2/30
 - 49s - loss: 1.4763 - acc: 0.4823 - val_loss: 1.7222 - val_acc: 0.4232
Epoch 3/30
 - 49s - loss: 1.1962 - acc: 0.5756 - val_loss: 1.2416 - val_acc: 0.5630
Epoch 4/30
 - 49s - loss: 1.0314 - acc: 0.6318 - val_loss: 1.3533 - val_acc: 0.5462
Epoch 5/30
 - 48s - loss: 0.9237 - acc: 0.6719 - val_loss: 1.0455 - val_acc: 0.6372
Epoch 6/30
 - 49s - loss: 0.8429 - acc: 0.7009 - val_loss: 1.0912 - val_acc: 0.6204
Epoch 7/30
 - 49s - loss: 0.7798 - acc: 0.7218 - val_loss: 0.9443 - val_acc: 0.6728
Epoch 8/30
 - 48s - loss: 0.7259 - acc: 0.7432 - val_loss: 1.0428 - val_acc: 0.6450
Epoch 9/30
 - 48s - loss: 0.6757 - acc: 0.7612 - val_loss: 0.8458 - val_acc: 0.7072
Epoch 10/30
 - 49s - loss: 0.6254 - acc: 0.7801 - val_loss: 0.7515 - val_acc: 0.7408
Epoch 11/30
 - 48s - loss: 0.5853 - acc: 0.7968 - val_loss: 0.8730 - val_acc: 0.7104
Epoch 12/30
 - 49s - loss: 0.5464 - acc: 0.8068 - val_loss: 0.9951 - val_acc: 0.6874
Epoch 13/30
 - 49s - loss: 0.5088 - acc: 0.8224 - val_loss: 1.1700 - val_acc: 0.6304
Epoch 14/30
 - 49s - loss: 0.4805 - acc: 0.8307 - val_loss: 0.8542 - val_acc: 0.7192
Epoch 15/30
 - 49s - loss: 0.4458 - acc: 0.8438 - val_loss: 0.7498 - val_acc: 0.7556
Epoch 16/30
 - 49s - loss: 0.4168 - acc: 0.8550 - val_loss: 0.7828 - val_acc: 0.7492
Epoch 17/30
 - 49s - loss: 0.3936 - acc: 0.8633 - val_loss: 0.8189 - val_acc: 0.7418
Epoch 18/30
 - 49s - loss: 0.3640 - acc: 0.8734 - val_loss: 0.8655 - val_acc: 0.7382
Epoch 19/30
 - 49s - loss: 0.3370 - acc: 0.8838 - val_loss: 0.9602 - val_acc: 0.7166
Epoch 20/30
 - 49s - loss: 0.3183 - acc: 0.8910 - val_loss: 0.6657 - val_acc: 0.7808
Epoch 21/30
 - 49s - loss: 0.2914 - acc: 0.8989 - val_loss: 0.8981 - val_acc: 0.7340
Epoch 22/30
 - 49s - loss: 0.2743 - acc: 0.9040 - val_loss: 0.7501 - val_acc: 0.7716
Epoch 23/30
 - 49s - loss: 0.2545 - acc: 0.9110 - val_loss: 1.5564 - val_acc: 0.6276
Epoch 24/30
 - 48s - loss: 0.2319 - acc: 0.9203 - val_loss: 0.7398 - val_acc: 0.7810
Epoch 25/30
 - 48s - loss: 0.2157 - acc: 0.9254 - val_loss: 0.8416 - val_acc: 0.7638
Epoch 26/30
 - 48s - loss: 0.1995 - acc: 0.9319 - val_loss: 0.7030 - val_acc: 0.7962
Epoch 27/30
 - 48s - loss: 0.1829 - acc: 0.9373 - val_loss: 0.7040 - val_acc: 0.8006
Epoch 28/30
 - 48s - loss: 0.1714 - acc: 0.9418 - val_loss: 0.8341 - val_acc: 0.7772
Epoch 29/30
 - 48s - loss: 0.1551 - acc: 0.9470 - val_loss: 0.7662 - val_acc: 0.7942
Epoch 30/30
 - 48s - loss: 0.1416 - acc: 0.9512 - val_loss: 0.8314 - val_acc: 0.7752
1465.6057908535004
--------
{'val_loss': [1.9175574256896972, 1.7221723190307616, 1.241611289215088, 1.35329829788208, 1.0454657455444336, 1.091198180770874, 0.9442800632476807, 1.0427942435264588, 0.8458066020965577, 0.7515402458190918, 0.8729567319869995, 0.9950898067474365, 1.1699662292480468, 0.8541856803894043, 0.7498254354476929, 0.7828155110359192, 0.8188551359176636, 0.8655181560516357, 0.9602186773300171, 0.6656930042266845, 0.8980857749938965, 0.7501155111312866, 1.5563838920593263, 0.7397634389877319, 0.8415788280487061, 0.7030229949951172, 0.7040033701896667, 0.8340851229667664, 0.7661952919006347, 0.8313706793785095], 'val_acc': [0.318, 0.4232, 0.563, 0.5462, 0.6372, 0.6204, 0.6728, 0.645, 0.7072, 0.7408, 0.7104, 0.6874, 0.6304, 0.7192, 0.7556, 0.7492, 0.7418, 0.7382, 0.7166, 0.7808, 0.734, 0.7716, 0.6276, 0.781, 0.7638, 0.7962, 0.8006, 0.7772, 0.7942, 0.7752], 'loss': [3.1108187816196016, 1.4762564366234674, 1.1962000763787164, 1.0314204651938543, 0.9236808397187127, 0.8428833906491597, 0.7798109399795532, 0.7258834878603617, 0.6756663847181532, 0.6253748341030545, 0.5853218545277914, 0.5463857115215726, 0.5087893130302429, 0.4805487550947401, 0.4457849095609453, 0.41678206992679173, 0.39357716387112934, 0.3640207250912984, 0.3369754618697696, 0.31827941479153105, 0.29141798458099366, 0.27433616857528687, 0.2544555418756273, 0.23185319616529676, 0.21566658301353456, 0.1994601772069931, 0.18285728381474814, 0.17139814357492658, 0.15508147615591686, 0.1416013273662991], 'acc': [0.3131111111058129, 0.48228888891008165, 0.5756, 0.6318222222540114, 0.6719333333651225, 0.7009333333545261, 0.7218222222540114, 0.7432222222116258, 0.7611777777671814, 0.7801111111005147, 0.7967555555873447, 0.8068222222116258, 0.8223555555237664, 0.8306888888782925, 0.8438444444656372, 0.8550222222646078, 0.8632666667090522, 0.8733555555767483, 0.8838222222328186, 0.8909555555767483, 0.8989333333015442, 0.9040000000211927, 0.9109777778201633, 0.9203111111429002, 0.9254000000423855, 0.9318666667090522, 0.9372666667090522, 0.94175555551317, 0.9470222221904331, 0.9511555555237664]}
===Final Test Score===
Test loss: 0.8531717727661133
Test accuracy: 0.7702
