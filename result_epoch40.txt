[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 2810190648415251348
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 9221513605996895663
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 5813472964521031642
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 617016870423568270
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17785387661969970818
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 6129082699201470287
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 5257759193440803445
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 10712378567349970806
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 7743499478935764275
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 1279297996001454576
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 128)  18560       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 128)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 128)  0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 128)  147584      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 128)  2176        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 128)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 128)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 128)  147584      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 128)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 128)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 128)  147584      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 128)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 128)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 128)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 128)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 128)  147584      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 128)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 128)  147584      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 128)  0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 128)  512         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 128)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 128)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 256)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 256)  33024       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 256)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 256)  590080      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 256)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 256)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 256)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 256)  590080      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 256)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 256)  0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 256)  590080      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 256)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 256)  590080      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 256)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 256)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 256)  590080      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 256)  1024        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 256)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 256)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 256)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 512)    2048        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 512)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 512)    0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 512)    2048        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 512)    131584      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 512)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 512)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 512)    2359808     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 512)    2048        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 512)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 512)    0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 512)    2048        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 512)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 512)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 512)    2359808     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 512)    2048        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 512)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 512)    0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 512)    2048        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 512)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 512)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 512)    2359808     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 512)    2048        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 512)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 8, 8, 512)    0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 512)    2359808     dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 512)    2048        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 512)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 512)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 512)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           5130        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 23,377,290
Trainable params: 23,362,922
Non-trainable params: 14,368
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/40
 - 57s - loss: 3.2695 - acc: 0.3056 - val_loss: 1.8153 - val_acc: 0.3840
Epoch 2/40
 - 49s - loss: 1.5394 - acc: 0.4668 - val_loss: 1.7036 - val_acc: 0.4150
Epoch 3/40
 - 48s - loss: 1.3124 - acc: 0.5410 - val_loss: 1.4735 - val_acc: 0.4894
Epoch 4/40
 - 49s - loss: 1.1190 - acc: 0.6022 - val_loss: 1.1293 - val_acc: 0.6044
Epoch 5/40
 - 49s - loss: 0.9907 - acc: 0.6493 - val_loss: 1.2352 - val_acc: 0.5730
Epoch 6/40
 - 49s - loss: 0.8797 - acc: 0.6882 - val_loss: 1.1676 - val_acc: 0.6016
Epoch 7/40
 - 49s - loss: 0.8092 - acc: 0.7141 - val_loss: 1.2924 - val_acc: 0.5902
Epoch 8/40
 - 49s - loss: 0.7501 - acc: 0.7350 - val_loss: 1.0704 - val_acc: 0.6396
Epoch 9/40
 - 49s - loss: 0.6913 - acc: 0.7583 - val_loss: 0.9744 - val_acc: 0.6734
Epoch 10/40
 - 49s - loss: 0.6431 - acc: 0.7736 - val_loss: 0.9774 - val_acc: 0.6730
Epoch 11/40
 - 49s - loss: 0.5971 - acc: 0.7904 - val_loss: 0.9727 - val_acc: 0.6828
Epoch 12/40
 - 49s - loss: 0.5571 - acc: 0.8063 - val_loss: 1.0461 - val_acc: 0.6792
Epoch 13/40
 - 49s - loss: 0.5179 - acc: 0.8177 - val_loss: 0.8746 - val_acc: 0.7042
Epoch 14/40
 - 49s - loss: 0.4872 - acc: 0.8296 - val_loss: 0.8236 - val_acc: 0.7336
Epoch 15/40
 - 49s - loss: 0.4491 - acc: 0.8448 - val_loss: 0.8076 - val_acc: 0.7410
Epoch 16/40
 - 49s - loss: 0.4186 - acc: 0.8539 - val_loss: 0.9310 - val_acc: 0.7218
Epoch 17/40
 - 49s - loss: 0.3947 - acc: 0.8617 - val_loss: 0.6720 - val_acc: 0.7800
Epoch 18/40
 - 49s - loss: 0.3672 - acc: 0.8725 - val_loss: 0.9416 - val_acc: 0.7192
Epoch 19/40
 - 49s - loss: 0.3415 - acc: 0.8816 - val_loss: 0.8603 - val_acc: 0.7508
Epoch 20/40
 - 49s - loss: 0.3169 - acc: 0.8917 - val_loss: 0.8227 - val_acc: 0.7476
Epoch 21/40
 - 49s - loss: 0.2956 - acc: 0.8978 - val_loss: 0.8267 - val_acc: 0.7592
Epoch 22/40
 - 49s - loss: 0.2718 - acc: 0.9056 - val_loss: 0.8249 - val_acc: 0.7640
Epoch 23/40
 - 49s - loss: 0.2512 - acc: 0.9142 - val_loss: 0.8726 - val_acc: 0.7548
Epoch 24/40
 - 49s - loss: 0.2370 - acc: 0.9178 - val_loss: 0.8092 - val_acc: 0.7722
Epoch 25/40
 - 49s - loss: 0.2149 - acc: 0.9254 - val_loss: 0.8537 - val_acc: 0.7698
Epoch 26/40
 - 49s - loss: 0.2009 - acc: 0.9308 - val_loss: 0.8720 - val_acc: 0.7534
Epoch 27/40
 - 49s - loss: 0.1854 - acc: 0.9367 - val_loss: 0.7604 - val_acc: 0.7998
Epoch 28/40
 - 49s - loss: 0.1709 - acc: 0.9416 - val_loss: 0.7903 - val_acc: 0.7842
Epoch 29/40
 - 49s - loss: 0.1557 - acc: 0.9471 - val_loss: 0.7804 - val_acc: 0.7906
Epoch 30/40
 - 49s - loss: 0.1432 - acc: 0.9518 - val_loss: 0.8320 - val_acc: 0.7834
Epoch 31/40
 - 49s - loss: 0.1305 - acc: 0.9561 - val_loss: 1.1388 - val_acc: 0.7442
Epoch 32/40
 - 49s - loss: 0.1258 - acc: 0.9575 - val_loss: 1.0242 - val_acc: 0.7450
Epoch 33/40
 - 49s - loss: 0.1134 - acc: 0.9624 - val_loss: 0.8776 - val_acc: 0.7906
Epoch 34/40
 - 49s - loss: 0.1028 - acc: 0.9672 - val_loss: 0.8720 - val_acc: 0.7922
Epoch 35/40
 - 49s - loss: 0.0952 - acc: 0.9688 - val_loss: 0.7699 - val_acc: 0.8128
Epoch 36/40
 - 48s - loss: 0.0884 - acc: 0.9718 - val_loss: 1.1509 - val_acc: 0.7554
Epoch 37/40
 - 49s - loss: 0.0812 - acc: 0.9733 - val_loss: 1.0065 - val_acc: 0.7718
Epoch 38/40
 - 48s - loss: 0.0724 - acc: 0.9766 - val_loss: 0.7741 - val_acc: 0.8116
Epoch 39/40
 - 49s - loss: 0.0694 - acc: 0.9778 - val_loss: 0.8492 - val_acc: 0.8034
Epoch 40/40
 - 49s - loss: 0.0707 - acc: 0.9771 - val_loss: 0.8769 - val_acc: 0.7960
1953.8681869506836
--------
{'val_loss': [1.8152761047363282, 1.7035600168228149, 1.4735042320251466, 1.1293400283813477, 1.2352311332702637, 1.167588631439209, 1.2923545162200927, 1.0703795543670653, 0.9744144678115845, 0.9773906930923462, 0.9727123791694641, 1.0461298536300658, 0.8746121007919312, 0.8235894557952881, 0.8075803422927856, 0.931031625366211, 0.6720447948455811, 0.9415833749771119, 0.8603004650115966, 0.8227206709861755, 0.8266808799743652, 0.8249110977172851, 0.8726382795333862, 0.8091735048294068, 0.8536573470592499, 0.872010884475708, 0.7603531558990478, 0.7903111988067627, 0.7803661173820495, 0.8320411781311036, 1.1387541737556457, 1.0241666000366212, 0.8776391820907593, 0.8720059406280518, 0.7698862266540527, 1.1508646083831786, 1.0064908073425294, 0.7741410610198974, 0.8491855627059937, 0.8768503902435303], 'val_acc': [0.384, 0.415, 0.4894, 0.6044, 0.573, 0.6016, 0.5902, 0.6396, 0.6734, 0.673, 0.6828, 0.6792, 0.7042, 0.7336, 0.741, 0.7218, 0.78, 0.7192, 0.7508, 0.7476, 0.7592, 0.764, 0.7548, 0.7722, 0.7698, 0.7534, 0.7998, 0.7842, 0.7906, 0.7834, 0.7442, 0.745, 0.7906, 0.7922, 0.8128, 0.7554, 0.7718, 0.8116, 0.8034, 0.796], 'loss': [3.269485706308153, 1.5394354281107585, 1.3123979036119249, 1.1189774362564087, 0.9906781812879775, 0.8797433154318067, 0.8091617997487386, 0.7501025419023302, 0.6912879068904453, 0.6430968714502122, 0.5971118973731995, 0.5571403050422669, 0.5179252700169881, 0.4872474515385098, 0.4491052763726976, 0.41864885093900894, 0.39472614585028754, 0.3671879368358188, 0.34154752774768404, 0.3169329398420122, 0.29559129031499226, 0.2717844851705763, 0.2512443924268087, 0.23697446807225545, 0.21487010252210828, 0.2008696179204517, 0.18543325464990404, 0.17085074463950264, 0.15567397294044494, 0.1432176304101944, 0.1304691954056422, 0.1257544961505466, 0.11341772096157074, 0.10276300638781653, 0.09524668615659078, 0.08836638918452792, 0.08124940798547532, 0.07239892894956801, 0.06941869315372573, 0.07065085643132528], 'acc': [0.30555555554495917, 0.466777777756585, 0.5409777778095669, 0.6021555555767483, 0.6492666666984558, 0.6882000000423856, 0.7141111111005147, 0.7349555555555556, 0.7583111110899183, 0.7736222222540113, 0.7904000000423855, 0.8063333333757189, 0.8177111110793219, 0.8296222221798367, 0.8448, 0.8538888888994852, 0.8616888889100817, 0.8724888888465033, 0.8815999999682108, 0.8916888888676961, 0.8977777777989705, 0.9055777777989705, 0.9142444444444444, 0.9177999999576145, 0.9253777777671814, 0.9308444444020589, 0.9367333333333333, 0.941644444402059, 0.9471111111534967, 0.951777777756585, 0.9560888888570998, 0.9574888888676961, 0.9624444444126553, 0.9672000000211928, 0.9688222222010294, 0.9718444444232517, 0.973333333322737, 0.9766222222010295, 0.9778222222222223, 0.9771111111005147]}
===Final Test Score===
Test loss: 0.8628387350559235
Test accuracy: 0.7967
