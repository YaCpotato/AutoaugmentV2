[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 7598911806108204634
, name: "/device:XLA_GPU:0"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17655721896691736728
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:1"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 7931901000022925985
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:2"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 17864463134448952050
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_GPU:3"
device_type: "XLA_GPU"
memory_limit: 17179869184
locality {
}
incarnation: 3225861171330041473
physical_device_desc: "device: XLA_GPU device"
, name: "/device:XLA_CPU:0"
device_type: "XLA_CPU"
memory_limit: 17179869184
locality {
}
incarnation: 17307226702921449094
physical_device_desc: "device: XLA_CPU device"
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 14471663734518196353
physical_device_desc: "device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3d:00.0, compute capability: 7.0"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 18411607569267921373
physical_device_desc: "device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3e:00.0, compute capability: 7.0"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 3
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 13032308322231015122
physical_device_desc: "device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b1:00.0, compute capability: 7.0"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 15651651584
locality {
  bus_id: 2
  numa_node: 1
  links {
    link {
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 1
      type: "StreamExecutor"
      strength: 1
    }
    link {
      device_id: 2
      type: "StreamExecutor"
      strength: 1
    }
  }
}
incarnation: 10422584993660670932
physical_device_desc: "device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:b2:00.0, compute capability: 7.0"
]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 32, 160)  0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 32, 32, 160)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 32, 32, 160)  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 32, 32, 160)  0           activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 320)  0           activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 320)  0           activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 320)  0           activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 16, 16, 320)  0           activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 640)    0           activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 640)    0           activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 640)    0           activation_22[0][0]              
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_11[0][0]                 
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 8, 8, 640)    0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
Train on 45000 samples, validate on 5000 samples
Epoch 1/50
 - 79s - loss: 3.4859 - acc: 0.2983 - val_loss: 1.8400 - val_acc: 0.3614
Epoch 2/50
 - 70s - loss: 1.5387 - acc: 0.4683 - val_loss: 1.6615 - val_acc: 0.4438
Epoch 3/50
 - 70s - loss: 1.3162 - acc: 0.5437 - val_loss: 1.4212 - val_acc: 0.5310
Epoch 4/50
 - 70s - loss: 1.1374 - acc: 0.6027 - val_loss: 1.3667 - val_acc: 0.5176
Epoch 5/50
 - 70s - loss: 0.9876 - acc: 0.6510 - val_loss: 1.2859 - val_acc: 0.5856
Epoch 6/50
 - 70s - loss: 0.8749 - acc: 0.6909 - val_loss: 1.1038 - val_acc: 0.6234
Epoch 7/50
 - 70s - loss: 0.7937 - acc: 0.7187 - val_loss: 0.9607 - val_acc: 0.6684
Epoch 8/50
 - 70s - loss: 0.7262 - acc: 0.7446 - val_loss: 0.8925 - val_acc: 0.6942
Epoch 9/50
 - 70s - loss: 0.6703 - acc: 0.7624 - val_loss: 0.8696 - val_acc: 0.7094
Epoch 10/50
 - 70s - loss: 0.6150 - acc: 0.7839 - val_loss: 1.5223 - val_acc: 0.5356
Epoch 11/50
 - 70s - loss: 0.5695 - acc: 0.8007 - val_loss: 0.9749 - val_acc: 0.6820
Epoch 12/50
 - 70s - loss: 0.5337 - acc: 0.8119 - val_loss: 0.9216 - val_acc: 0.7120
Epoch 13/50
 - 70s - loss: 0.4929 - acc: 0.8263 - val_loss: 1.2078 - val_acc: 0.6498
Epoch 14/50
 - 70s - loss: 0.4582 - acc: 0.8396 - val_loss: 0.9060 - val_acc: 0.7102
Epoch 15/50
 - 70s - loss: 0.4250 - acc: 0.8518 - val_loss: 0.7652 - val_acc: 0.7574
Epoch 16/50
 - 70s - loss: 0.3957 - acc: 0.8621 - val_loss: 0.8621 - val_acc: 0.7350
Epoch 17/50
 - 70s - loss: 0.3659 - acc: 0.8731 - val_loss: 0.9376 - val_acc: 0.7326
Epoch 18/50
 - 70s - loss: 0.3433 - acc: 0.8806 - val_loss: 0.8044 - val_acc: 0.7558
Epoch 19/50
 - 70s - loss: 0.3135 - acc: 0.8922 - val_loss: 1.0012 - val_acc: 0.7190
Epoch 20/50
 - 70s - loss: 0.2903 - acc: 0.9003 - val_loss: 0.7738 - val_acc: 0.7758
Epoch 21/50
 - 70s - loss: 0.2690 - acc: 0.9051 - val_loss: 0.9500 - val_acc: 0.7404
Epoch 22/50
 - 70s - loss: 0.2452 - acc: 0.9148 - val_loss: 0.7487 - val_acc: 0.7820
Epoch 23/50
 - 70s - loss: 0.2275 - acc: 0.9199 - val_loss: 1.3154 - val_acc: 0.6660
Epoch 24/50
 - 70s - loss: 0.2071 - acc: 0.9285 - val_loss: 0.8801 - val_acc: 0.7506
Epoch 25/50
 - 70s - loss: 0.1919 - acc: 0.9343 - val_loss: 0.7413 - val_acc: 0.7900
Epoch 26/50
 - 70s - loss: 0.1748 - acc: 0.9409 - val_loss: 0.8219 - val_acc: 0.7818
Epoch 27/50
 - 70s - loss: 0.1566 - acc: 0.9478 - val_loss: 1.0116 - val_acc: 0.7442
Epoch 28/50
 - 70s - loss: 0.1429 - acc: 0.9520 - val_loss: 1.1104 - val_acc: 0.7452
Epoch 29/50
 - 70s - loss: 0.1327 - acc: 0.9553 - val_loss: 0.7589 - val_acc: 0.7988
Epoch 30/50
 - 70s - loss: 0.1205 - acc: 0.9594 - val_loss: 0.8436 - val_acc: 0.7850
Epoch 31/50
 - 70s - loss: 0.1099 - acc: 0.9641 - val_loss: 0.7570 - val_acc: 0.8122
Epoch 32/50
 - 70s - loss: 0.0970 - acc: 0.9683 - val_loss: 0.9959 - val_acc: 0.7732
Epoch 33/50
 - 70s - loss: 0.0871 - acc: 0.9716 - val_loss: 1.1120 - val_acc: 0.7620
Epoch 34/50
 - 70s - loss: 0.0816 - acc: 0.9737 - val_loss: 0.9434 - val_acc: 0.7838
Epoch 35/50
 - 70s - loss: 0.0779 - acc: 0.9758 - val_loss: 0.8562 - val_acc: 0.7948
Epoch 36/50
 - 70s - loss: 0.0691 - acc: 0.9782 - val_loss: 0.8554 - val_acc: 0.7974
Epoch 37/50
 - 70s - loss: 0.0653 - acc: 0.9796 - val_loss: 0.8524 - val_acc: 0.8040
Epoch 38/50
 - 70s - loss: 0.0593 - acc: 0.9819 - val_loss: 1.0001 - val_acc: 0.7706
Epoch 39/50
 - 70s - loss: 0.0553 - acc: 0.9833 - val_loss: 0.8953 - val_acc: 0.7996
Epoch 40/50
 - 70s - loss: 0.0488 - acc: 0.9852 - val_loss: 0.9938 - val_acc: 0.7812
Epoch 41/50
 - 70s - loss: 0.0491 - acc: 0.9847 - val_loss: 1.1965 - val_acc: 0.7640
Epoch 42/50
 - 70s - loss: 0.0439 - acc: 0.9864 - val_loss: 0.8401 - val_acc: 0.8148
Epoch 43/50
 - 70s - loss: 0.0393 - acc: 0.9891 - val_loss: 0.8638 - val_acc: 0.8150
Epoch 44/50
 - 70s - loss: 0.0372 - acc: 0.9897 - val_loss: 0.9018 - val_acc: 0.8094
Epoch 45/50
 - 70s - loss: 0.0357 - acc: 0.9896 - val_loss: 1.1109 - val_acc: 0.7968
Epoch 46/50
 - 70s - loss: 0.0328 - acc: 0.9911 - val_loss: 0.9468 - val_acc: 0.8060
Epoch 47/50
 - 70s - loss: 0.0324 - acc: 0.9908 - val_loss: 1.0344 - val_acc: 0.7972
Epoch 48/50
 - 70s - loss: 0.0305 - acc: 0.9916 - val_loss: 1.0667 - val_acc: 0.7838
Epoch 49/50
 - 70s - loss: 0.0289 - acc: 0.9923 - val_loss: 0.7865 - val_acc: 0.8300
Epoch 50/50
 - 70s - loss: 0.0282 - acc: 0.9920 - val_loss: 0.8112 - val_acc: 0.8342
3523.678293466568
--------
{'val_loss': [1.8399755065917969, 1.6615041233062744, 1.421231974029541, 1.3666938499450683, 1.285889154815674, 1.1037836471557618, 0.9607179372787475, 0.892537347984314, 0.8695617855072022, 1.5223250200271607, 0.9749418266296387, 0.9215851898193359, 1.2078263580322266, 0.9059967065811158, 0.7652233840942383, 0.8620952520370483, 0.9376368782043457, 0.8043574306488037, 1.001219358444214, 0.7738176984786987, 0.9499711742401123, 0.7487256927490235, 1.3154495470046996, 0.8800724090576172, 0.7412921474456787, 0.8219050581932068, 1.0115507390022278, 1.110434259223938, 0.7588543451309204, 0.8435818855285645, 0.7569921442985534, 0.9958746578216553, 1.1120438203811644, 0.943412755393982, 0.8561966636657715, 0.8554234838485718, 0.8524218017578125, 1.0000760292053223, 0.8952530460357666, 0.9938173166275024, 1.196454079246521, 0.8400503601074218, 0.8638118064880371, 0.9018395336151123, 1.1108515407562256, 0.9468107561111451, 1.0343797424316405, 1.0666905067443848, 0.7864862939834595, 0.8111921768188477], 'val_acc': [0.3614, 0.4438, 0.531, 0.5176, 0.5856, 0.6234, 0.6684, 0.6942, 0.7094, 0.5356, 0.682, 0.712, 0.6498, 0.7102, 0.7574, 0.735, 0.7326, 0.7558, 0.719, 0.7758, 0.7404, 0.782, 0.666, 0.7506, 0.79, 0.7818, 0.7442, 0.7452, 0.7988, 0.785, 0.8122, 0.7732, 0.762, 0.7838, 0.7948, 0.7974, 0.804, 0.7706, 0.7996, 0.7812, 0.764, 0.8148, 0.815, 0.8094, 0.7968, 0.806, 0.7972, 0.7838, 0.83, 0.8342], 'loss': [3.4859263554255167, 1.5386589127222696, 1.3162015892028809, 1.137359680006239, 0.9876107950422499, 0.8749155263053047, 0.7937246494293213, 0.7262277236726549, 0.6702622222582499, 0.6150428209304809, 0.5694558699078031, 0.5336662611060672, 0.49290615232785545, 0.4581772582266066, 0.42497688932418826, 0.39568504938019644, 0.3658517343680064, 0.34330276634958057, 0.3135155489020877, 0.29034412033292983, 0.26895130971272785, 0.24517884483867222, 0.22745068407058716, 0.20710102915763856, 0.19193251395755345, 0.17479189748764037, 0.15663369465933905, 0.1429264109081692, 0.13265718173715804, 0.12051643299791548, 0.10993128803438611, 0.09698360658619139, 0.08709698940647972, 0.08164876126845677, 0.07793494292497635, 0.06910645974874496, 0.06529806018140581, 0.05934709159003364, 0.055279450602001616, 0.04876604445642895, 0.0491394031908777, 0.04392429744005203, 0.03930372304121653, 0.037168182749880686, 0.03574640512069066, 0.032762053212854594, 0.032369924415482414, 0.030538906627231174, 0.02889936982658174, 0.028158903981579674], 'acc': [0.29833333332803513, 0.4682888889312744, 0.5437111111005147, 0.6026666666348776, 0.6509777777353922, 0.6909333333015442, 0.7186666666878594, 0.7446444444762336, 0.7624000000105964, 0.7838666666348775, 0.8007333333757188, 0.8119111111217074, 0.826333333322737, 0.8395999999682109, 0.8518222222116258, 0.8620888889100816, 0.8730666666454739, 0.8805777777883742, 0.8922222222010294, 0.9003333333545261, 0.9051111111217075, 0.9148444444762336, 0.919866666677263, 0.9284888888994852, 0.9343333333015442, 0.9408888888465033, 0.94775555551317, 0.9519777778201634, 0.9553333333015442, 0.9594444444656373, 0.9641111110899183, 0.9682666666560703, 0.9715999999788072, 0.9737333333227369, 0.975777777756585, 0.9782222222116258, 0.9795555555449592, 0.9819111110687256, 0.9833111110687256, 0.985177777756585, 0.9847333333227369, 0.9863777777671814, 0.9891333333121406, 0.9897333333227369, 0.9895999999682109, 0.9911333333227369, 0.9908222222010294, 0.9916, 0.9923333333333333, 0.9919555555555556]}
===Final Test Score===
Test loss: 0.8156488074064254
Test accuracy: 0.8232
